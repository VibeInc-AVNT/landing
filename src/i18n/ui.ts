export const languages = {
	en: "English",
	it: "Italiano",
};

export const defaultLang = "en";

export const ui = {
	en: {
		or: "or",
		contact: "Contact Us",
		contacts: "Contact",
		contactus: "Get in Touch",
		projects: "Projects",
		services: "Features",
		homepage: "Homepage",
		// Warning Banner
		"warning.message": "Vibe is currently in development and seeking funding. No nodes are online yet.",
		"warning.cta": "Contact Us for More Info",
		tagline:
			"The future of AI caching infrastructure - coming soon.",
		"projects.yours": "Your project",
		"projects.see": "See project",
		"hero.title.main": "AI that will respond",
		"hero.highlight.one": "instantly",
		"hero.highlight.two": "affordably",
		"hero.title.1": "Instant",
		"hero.title.2": "Smart",
		"hero.title.3": "Fast",
		"hero.title.4": "Cached",
		"hero.subtitle":
			"Smart caching infrastructure that will make AI applications faster and more cost-effective - coming soon.",
		"hero.scroll": "Learn more",
		// Problem Section
		"problem.title": "The problem we're solving",
		"problem.1.stat": "2-5s",
		"problem.1.title": "Slow Response Times",
		"problem.1.desc": "Every AI request takes too long, frustrating users and killing conversions",
		"problem.2.stat": "$200K+",
		"problem.2.title": "Exploding Costs",
		"problem.2.desc": "API costs scale linearly with usage, making AI prohibitively expensive",
		"problem.3.stat": "40%",
		"problem.3.title": "Redundant Processing",
		"problem.3.desc": "The same questions are asked repeatedly, wasting compute and money",
		// How It Works Section
		"howitworks.title": "How It Works",
		"howitworks.1.step": "01",
		"howitworks.1.title": "Intercept",
		"howitworks.1.desc": "Requests route through our edge network. Zero code changes required.",
		"howitworks.2.step": "02",
		"howitworks.2.title": "Understand",
		"howitworks.2.desc": "Our semantic engine analyzes meaning, not just text.",
		"howitworks.3.step": "03",
		"howitworks.3.title": "Match",
		"howitworks.3.desc": "Compare against billions of cached responses with industry-leading accuracy.",
		"howitworks.4.step": "04",
		"howitworks.4.title": "Deliver",
		"howitworks.4.desc": "Cache hit = 50ms response. Cache miss = forward to LLM and cache result.",
		// Features Section
		"features.title": "Planned Features",
		"feature.1.title": "Semantic Understanding",
		"feature.1.content": "AI will comprehend meaning, not just text. Similar queries will return cached responses even when phrased differently.",
		"feature.2.title": "Global Edge Network",
		"feature.2.content": "Planned 200+ edge locations worldwide to ensure users get lightning-fast responses wherever they are.",
		"feature.3.title": "Zero Trust Security",
		"feature.3.content": "End-to-end encryption, SOC 2 compliance planned, and we will never train on your data.",
		"feature.4.title": "Provider Agnostic",
		"feature.4.content": "Designed to work seamlessly with OpenAI, Anthropic, Google, Cohere, and any other LLM provider.",
		"feature.5.title": "Real-Time Analytics",
		"feature.5.content": "Track hit rates, latency metrics, and cost savings with our planned comprehensive dashboard.",
		"feature.6.title": "Automatic Failover",
		"feature.6.content": "Transparent routing if issues occur. Your users will never experience downtime.",
		// Comparison Section
		"comparison.title": "The Vision",
		"comparison.without": "Traditional AI",
		"comparison.with": "With Vibe Cache (Planned)",
		"comparison.response": "Response Time",
		"comparison.cost": "Monthly Cost (10M req)",
		"comparison.hitrate": "Cache Hit Rate",
		"comparison.latency": "Global Latency",
		"comparison.without.response": "2,000ms",
		"comparison.without.cost": "$200,000",
		"comparison.without.hitrate": "0-5%",
		"comparison.without.latency": "Variable",
		"comparison.with.response": "50ms",
		"comparison.with.cost": "$60,000",
		"comparison.with.hitrate": "40-60%",
		"comparison.with.latency": "<100ms",
		"comparison.improvement.response": "40× faster",
		"comparison.improvement.cost": "70% savings",
		"comparison.improvement.hitrate": "Semantic matching",
		"comparison.improvement.latency": "Everywhere",
		// Pricing Section
		"pricing.title": "Planned Pricing",
		"pricing.monthly": "Monthly",
		"pricing.annual": "Annual",
		"pricing.annual.save": "Save 20%",
		"pricing.starter.name": "Starter",
		"pricing.starter.price": "$99",
		"pricing.starter.period": "/month",
		"pricing.starter.requests": "1M requests/month",
		"pricing.starter.feature1": "5 edge regions",
		"pricing.starter.feature2": "Basic analytics",
		"pricing.starter.feature3": "Email support",
		"pricing.starter.feature4": "99.9% uptime SLA",
		"pricing.starter.cta": "Get Started",
		"pricing.growth.name": "Growth",
		"pricing.growth.price": "$499",
		"pricing.growth.period": "/month",
		"pricing.growth.requests": "10M requests/month",
		"pricing.growth.feature1": "50 edge regions",
		"pricing.growth.feature2": "Advanced analytics",
		"pricing.growth.feature3": "Priority support",
		"pricing.growth.feature4": "99.95% uptime SLA",
		"pricing.growth.cta": "Get Started",
		"pricing.growth.popular": "Most Popular",
		"pricing.enterprise.name": "Enterprise",
		"pricing.enterprise.price": "Custom",
		"pricing.enterprise.period": "",
		"pricing.enterprise.requests": "Unlimited requests",
		"pricing.enterprise.feature1": "200+ edge regions",
		"pricing.enterprise.feature2": "Dedicated support",
		"pricing.enterprise.feature3": "On-premise option",
		"pricing.enterprise.feature4": "99.99% uptime SLA",
		"pricing.enterprise.cta": "Contact Sales",
		// FAQ Section
		"faqs.question1": "How does semantic caching differ from traditional caching?",
		"faqs.answer1":
			"Traditional caching requires exact text matches. Our semantic cache understands meaning—so 'What's the weather?' and 'How's the weather today?' both hit the same cached response. This dramatically increases cache hit rates.",
		"faqs.question2": "How do I integrate Vibe Cache?",
		"faqs.answer2":
			"Simply change your API base URL to point to our service. That's it—no code changes, no SDK installation. Most teams are up and running in under 5 minutes.",
		"faqs.question3": "What LLM providers do you support?",
		"faqs.answer3":
			"We support all major providers including OpenAI, Anthropic (Claude), Google (Gemini), Cohere, Mistral, and any OpenAI-compatible API. Adding new providers is straightforward.",
		"faqs.question4": "Is my data secure?",
		"faqs.answer4":
			"Absolutely. We're SOC 2 Type II certified with end-to-end encryption. We never train on your data, and you can configure automatic data expiration policies. Enterprise customers can also opt for on-premise deployment.",
		"faqs.question5": "What if a cached response becomes stale or incorrect?",
		"faqs.answer5":
			"You have full control with configurable TTL (time-to-live), manual cache invalidation via API, and our purge endpoint for instant cache clearing. You can also exclude specific queries from caching entirely.",
		"faqs.question6": "Do you support streaming responses?",
		"faqs.answer6":
			"Yes! We support streaming for both cache hits and misses. Cached responses stream back instantly, while new responses stream through from your LLM provider and get cached for future requests.",
		"faqs.question7": "What's the pricing model?",
		"faqs.answer7":
			"You pay per request routed through our service, regardless of whether it's a cache hit or miss. Cache hits cost the same but save you the underlying LLM cost—that's where your real savings come from.",
		"faqs.question8": "When will Vibe Cache be available?",
		"faqs.answer8":
			"Vibe is currently in development and seeking funding. We have no nodes online yet. For more information about our progress and launch timeline, please contact us at support@avunite.com.",
		"faq.otherquestions": "Still have questions?",
		// CTA Section
		"cta.title": "Get in touch",
		"cta.subtitle": "Interested in our vision? Want to learn more or discuss funding opportunities? Reach out to the Vibe team.",
		"cta.primary": "Contact Us",
		"cta.secondary": "Email Us",
		"cta.trust": "",
		// General
		"thanks.subtitle": "We'll be in touch soon",
		"thanks.title": "Thank You",
		"thanks.content": "Our team will reach out within 24 hours to discuss your needs.",
		"privacy.wip": "Work in progress",
		"privacy.wip.content": "This page will be updated soon",
		"contact.title": "Get in Touch",
		"contact.subtitle": "Let's discuss how Vibe Cache can accelerate your AI applications",
		"contact.name": "Name",
		"contact.email": "Email",
		"contact.message": "Message",
		"contact.company": "Company",
		"contact.agree": "By sending this, you agree to our",
		"contact.send": "Send Message",
		"blog.title": "Blog",
		"blog.subtitle": "Insights on AI Infrastructure",
		"blog.gotoproject": "Read more",
		"footer.newsletter": "Stay updated on",
		"footer.newsletter2": "AI performance",
		"footer.yourmail": "Your email",
		// Navigation
		"nav.howitworks": "How It Works",
		"nav.features": "Features",
		"nav.pricing": "Pricing",
		"nav.faq": "FAQ",
		"nav.demo": "Request Demo",
		"nav.getstarted": "Get Started",
		// Footer sections
		"footer.product": "Product",
		"footer.company": "Company",
		"footer.resources": "Resources",
		"footer.legal": "Legal",
		"footer.status": "In Development - No Nodes Online",
	},
	it: {
		or: "o",
		contact: "Contattaci",
		contacts: "Contatti",
		contactus: "Mettiti in Contatto",
		projects: "Progetti",
		services: "Funzionalità",
		homepage: "Homepage",
		// Warning Banner
		"warning.message": "Vibe è attualmente in sviluppo e cerca finanziamenti. Nessun nodo è ancora online.",
		"warning.cta": "Contattaci per Maggiori Informazioni",
		tagline:
			"Il futuro dell'infrastruttura di caching AI - in arrivo.",
		"projects.yours": "Il tuo progetto",
		"projects.see": "Visualizza progetto",
		"hero.title.main": "Inferenza AI",
		"hero.title.1": "Istantanea",
		"hero.title.2": "Smart",
		"hero.title.3": "Veloce",
		"hero.title.4": "Cached",
		"hero.subtitle":
			"Infrastruttura di caching intelligente che renderà le applicazioni AI più veloci ed economiche - in arrivo.",
		"hero.scroll": "scopri di più",
		// Problem Section
		"problem.title": "Il problema che stiamo risolvendo",
		"problem.1.stat": "2-5s",
		"problem.1.title": "Tempi di Risposta Lenti",
		"problem.1.desc": "Ogni richiesta AI richiede troppo tempo, frustrando gli utenti",
		"problem.2.stat": "€200K+",
		"problem.2.title": "Costi Esplosivi",
		"problem.2.desc": "I costi API scalano linearmente con l'utilizzo",
		"problem.3.stat": "40%",
		"problem.3.title": "Elaborazione Ridondante",
		"problem.3.desc": "Le stesse domande vengono poste ripetutamente",
		// How It Works Section
		"howitworks.title": "Come Funziona",
		"howitworks.1.step": "01",
		"howitworks.1.title": "Intercetta",
		"howitworks.1.desc": "Le richieste passano attraverso la nostra rete edge. Zero modifiche al codice.",
		"howitworks.2.step": "02",
		"howitworks.2.title": "Comprende",
		"howitworks.2.desc": "Il nostro motore semantico analizza il significato, non solo il testo.",
		"howitworks.3.step": "03",
		"howitworks.3.title": "Abbina",
		"howitworks.3.desc": "Confronta con miliardi di risposte in cache con precisione leader nel settore.",
		"howitworks.4.step": "04",
		"howitworks.4.title": "Consegna",
		"howitworks.4.desc": "Cache hit = risposta in 50ms. Cache miss = inoltra all'LLM e salva in cache.",
		// Features Section
		"features.title": "Funzionalità Pianificate",
		"feature.1.title": "Comprensione Semantica",
		"feature.1.content": "L'AI comprenderà il significato, non solo il testo. Query simili restituiranno risposte in cache anche se formulate diversamente.",
		"feature.2.title": "Rete Edge Globale",
		"feature.2.content": "Pianificate 200+ località edge nel mondo per assicurare risposte fulminee ovunque si trovino i tuoi utenti.",
		"feature.3.title": "Sicurezza Zero Trust",
		"feature.3.content": "Crittografia end-to-end, certificazione SOC 2 pianificata, e non addestreremo mai sui tuoi dati.",
		"feature.4.title": "Provider Agnostico",
		"feature.4.content": "Progettato per funzionare con OpenAI, Anthropic, Google, Cohere e qualsiasi altro provider LLM.",
		"feature.5.title": "Analytics in Tempo Reale",
		"feature.5.content": "Monitora hit rate, metriche di latenza e risparmi con la nostra dashboard completa pianificata.",
		"feature.6.title": "Failover Automatico",
		"feature.6.content": "Routing trasparente in caso di problemi. I tuoi utenti non sperimenteranno mai downtime.",
		// Comparison Section
		"comparison.title": "La Visione",
		"comparison.without": "AI Tradizionale",
		"comparison.with": "Con Vibe Cache (Pianificato)",
		"comparison.response": "Tempo di Risposta",
		"comparison.cost": "Costo Mensile (10M req)",
		"comparison.hitrate": "Cache Hit Rate",
		"comparison.latency": "Latenza Globale",
		"comparison.without.response": "2.000ms",
		"comparison.without.cost": "€200.000",
		"comparison.without.hitrate": "0-5%",
		"comparison.without.latency": "Variabile",
		"comparison.with.response": "50ms",
		"comparison.with.cost": "€60.000",
		"comparison.with.hitrate": "40-60%",
		"comparison.with.latency": "<100ms",
		"comparison.improvement.response": "40× più veloce",
		"comparison.improvement.cost": "70% risparmio",
		"comparison.improvement.hitrate": "Matching semantico",
		"comparison.improvement.latency": "Ovunque",
		// Pricing Section
		"pricing.title": "Prezzi Pianificati",
		"pricing.monthly": "Mensile",
		"pricing.annual": "Annuale",
		"pricing.annual.save": "Risparmia 20%",
		"pricing.starter.name": "Starter",
		"pricing.starter.price": "€99",
		"pricing.starter.period": "/mese",
		"pricing.starter.requests": "1M richieste/mese",
		"pricing.starter.feature1": "5 regioni edge",
		"pricing.starter.feature2": "Analytics base",
		"pricing.starter.feature3": "Supporto email",
		"pricing.starter.feature4": "SLA uptime 99.9%",
		"pricing.starter.cta": "Inizia",
		"pricing.growth.name": "Growth",
		"pricing.growth.price": "€499",
		"pricing.growth.period": "/mese",
		"pricing.growth.requests": "10M richieste/mese",
		"pricing.growth.feature1": "50 regioni edge",
		"pricing.growth.feature2": "Analytics avanzate",
		"pricing.growth.feature3": "Supporto prioritario",
		"pricing.growth.feature4": "SLA uptime 99.95%",
		"pricing.growth.cta": "Inizia",
		"pricing.growth.popular": "Più Popolare",
		"pricing.enterprise.name": "Enterprise",
		"pricing.enterprise.price": "Custom",
		"pricing.enterprise.period": "",
		"pricing.enterprise.requests": "Richieste illimitate",
		"pricing.enterprise.feature1": "200+ regioni edge",
		"pricing.enterprise.feature2": "Supporto dedicato",
		"pricing.enterprise.feature3": "Opzione on-premise",
		"pricing.enterprise.feature4": "SLA uptime 99.99%",
		"pricing.enterprise.cta": "Contatta Vendite",
		// FAQ Section
		"faqs.question1": "Come differisce la cache semantica dalla cache tradizionale?",
		"faqs.answer1":
			"La cache tradizionale richiede corrispondenze testuali esatte. La nostra cache semantica comprende il significato—così 'Che tempo fa?' e 'Com'è il meteo oggi?' restituiscono la stessa risposta in cache.",
		"faqs.question2": "Come integro Vibe Cache?",
		"faqs.answer2":
			"Cambia semplicemente l'URL base della tua API per puntare al nostro servizio. Nessuna modifica al codice, nessuna installazione SDK. La maggior parte dei team è operativa in meno di 5 minuti.",
		"faqs.question3": "Quali provider LLM supportate?",
		"faqs.answer3":
			"Supportiamo tutti i principali provider inclusi OpenAI, Anthropic (Claude), Google (Gemini), Cohere, Mistral e qualsiasi API compatibile con OpenAI.",
		"faqs.question4": "I miei dati sono al sicuro?",
		"faqs.answer4":
			"Assolutamente. Siamo certificati SOC 2 Type II con crittografia end-to-end. Non addestriamo mai sui tuoi dati e puoi configurare policy di scadenza automatica.",
		"faqs.question5": "E se una risposta in cache diventa obsoleta o errata?",
		"faqs.answer5":
			"Hai il pieno controllo con TTL configurabile, invalidazione manuale della cache via API e il nostro endpoint di purge per la cancellazione istantanea.",
		"faqs.question6": "Supportate le risposte in streaming?",
		"faqs.answer6":
			"Sì! Supportiamo lo streaming sia per cache hit che miss. Le risposte in cache vengono inviate istantaneamente in streaming.",
		"faqs.question7": "Qual è il modello di pricing?",
		"faqs.answer7":
			"Paghi per richiesta instradata attraverso il nostro servizio. I cache hit costano lo stesso ma ti fanno risparmiare il costo LLM sottostante.",
		"faqs.question8": "Quando sarà disponibile Vibe Cache?",
		"faqs.answer8":
			"Vibe è attualmente in sviluppo e cerca finanziamenti. Non abbiamo ancora nodi online. Per maggiori informazioni sui nostri progressi e la timeline di lancio, contattaci a support@avunite.com.",
		"faq.otherquestions": "Altre domande?",
		// CTA Section
		"cta.title": "Mettiti in contatto",
		"cta.subtitle": "Interessato alla nostra visione? Vuoi saperne di più o discutere opportunità di finanziamento? Contatta il team Vibe.",
		"cta.primary": "Contattaci",
		"cta.secondary": "Inviaci un'email",
		// General
		"thanks.subtitle": "Ti contatteremo presto",
		"thanks.title": "Grazie",
		"thanks.content": "Il nostro team ti contatterà entro 24 ore.",
		"privacy.wip": "Lavori in corso",
		"privacy.wip.content": "Questa pagina verrà aggiornata a breve",
		"contact.title": "Contattaci",
		"contact.subtitle": "Parliamo di come Vibe Cache può accelerare le tue applicazioni AI",
		"contact.name": "Nome",
		"contact.email": "Email",
		"contact.message": "Messaggio",
		"contact.company": "Azienda",
		"contact.agree": "Inviando accetti la nostra",
		"contact.send": "Invia Messaggio",
		"blog.title": "Blog",
		"blog.subtitle": "Insights sull'Infrastruttura AI",
		"blog.gotoproject": "Leggi di più",
		"footer.newsletter": "Rimani aggiornato su",
		"footer.newsletter2": "performance AI",
		"footer.yourmail": "La tua email",
		// Navigation
		"nav.howitworks": "Come Funziona",
		"nav.features": "Funzionalità",
		"nav.pricing": "Prezzi",
		"nav.faq": "FAQ",
		"nav.demo": "Richiedi Demo",
		"nav.getstarted": "Inizia",
		// Footer sections
		"footer.product": "Prodotto",
		"footer.company": "Azienda",
		"footer.resources": "Risorse",
		"footer.legal": "Legale",
		"footer.status": "In Sviluppo - Nessun Nodo Online",
	},
} as const;

export const showDefaultLang = false;
