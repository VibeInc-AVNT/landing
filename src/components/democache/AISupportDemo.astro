---
---

<section id="ai-support-demo" class="section relative bg-white py-16">
	<div class="col-span-12">
		<div class="mx-auto max-w-4xl">
			<!-- Section Header -->
			<div class="mb-8 text-center">
				<h2 class="font-display text-3xl font-bold uppercase text-gray-900 md:text-4xl">
					AI Support Bot Demo
				</h2>
				<p class="mt-4 text-gray-600">
					Ask common customer support questions and see how semantic caching delivers instant responses.
				</p>
			</div>

			<!-- Demo Container -->
			<div class="neo-card bg-gray-50 p-6 lg:p-8">
				<!-- Chat messages -->
				<div id="support-chat" class="mb-6 h-96 overflow-y-auto rounded-lg bg-white p-4 space-y-4">
					<!-- Welcome message -->
					<div class="flex gap-3">
						<div class="flex-shrink-0 w-8 h-8 rounded-full bg-vibe-purple flex items-center justify-center text-white font-bold">
							AI
						</div>
						<div class="flex-1">
							<div class="neo-card bg-gray-100 p-3 text-sm">
								<p>ðŸ‘‹ Hi! I'm your AI support assistant. Ask me anything about our product, billing, or technical issues. Try asking similar questions to see semantic caching in action!</p>
							</div>
							<div class="mt-1 text-xs text-gray-500">Just now</div>
						</div>
					</div>
				</div>

				<!-- Quick questions -->
				<div class="mb-4">
					<div class="mb-2 text-sm font-bold text-gray-600">Quick Questions:</div>
					<div class="flex flex-wrap gap-2">
						<button class="quick-question-btn text-sm neo-btn bg-vibe-yellow px-4 py-2" data-question="How do I reset my password?">
							Reset password
						</button>
						<button class="quick-question-btn text-sm neo-btn bg-vibe-indigo text-white px-4 py-2" data-question="What are your pricing plans?">
							Pricing plans
						</button>
						<button class="quick-question-btn text-sm neo-btn bg-vibe-orange text-white px-4 py-2" data-question="How does semantic caching work?">
							How it works
						</button>
						<button class="quick-question-btn text-sm neo-btn bg-vibe-purple text-white px-4 py-2" data-question="Can I integrate with my existing API?">
							API integration
						</button>
					</div>
				</div>

				<!-- Input area -->
				<div class="flex gap-3">
					<input
						type="text"
						id="support-input"
						placeholder="Type your question here..."
						class="flex-1 rounded-lg border-4 border-black px-4 py-3 focus:outline-none focus:ring-2 focus:ring-vibe-purple"
					/>
					<button
						id="support-send-btn"
						class="neo-btn bg-vibe-purple px-6 py-3 font-bold text-white hover:bg-vibe-purple-600"
					>
						Send
					</button>
				</div>

				<!-- Loading indicator -->
				<div id="support-loading" class="mt-4 hidden">
					<div class="flex items-center gap-2 text-sm text-gray-600">
						<div class="h-4 w-4 animate-spin rounded-full border-2 border-vibe-purple border-t-transparent"></div>
						<span>Processing...</span>
					</div>
				</div>
			</div>
		</div>
	</div>
</section>

<script>
	// Real VibeCache API endpoint
	const VIBECACHE_API = 'http://localhost:8081/v1/chat/completions';
	const SUPPORT_MODEL = 'gpt-4o-mini';

	// System prompt for support bot
	const SUPPORT_SYSTEM_PROMPT = `You are a helpful AI support assistant for VibeCache, a semantic caching service for AI applications. 
	
Key information about VibeCache:
- Achieves 68% cache hit rates vs 10-15% for exact text matching
- Cache hits return in ~45ms vs ~1500ms for LLM calls (33x faster)
- Reduces API costs by 70% through intelligent semantic caching
- Works with OpenAI, Anthropic, Google, and Cohere
- Uses 384-dimensional embeddings with â‰¥0.80 cosine similarity threshold
- Pricing: Free tier (10K requests/month), Pro ($99/month for 1M requests), Enterprise (custom)
- API endpoint: https://cache.vibe.ai/v1/chat/completions (OpenAI-compatible)
- Contact: support@vibe.ai

Provide concise, helpful answers to customer questions about the product, billing, and technical issues.`;

	function addMessage(text, isUser = false, isHit = false, latency = 0) {
		const chatContainer = document.getElementById('support-chat');
		const messageDiv = document.createElement('div');
		messageDiv.className = 'flex gap-3';
		
		const time = new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' });
		
		if (isUser) {
			messageDiv.innerHTML = `
				<div class="flex-1"></div>
				<div class="flex-shrink-0 w-full max-w-[80%]">
					<div class="neo-card bg-vibe-purple text-white p-3 text-sm ml-auto">
						<p>${text}</p>
					</div>
					<div class="mt-1 text-xs text-gray-500 text-right">${time}</div>
				</div>
			`;
		} else {
			const badge = isHit 
				? `<span class="inline-flex items-center gap-1 rounded-full bg-vibe-yellow px-2 py-1 text-xs font-bold text-vibe-purple">âš¡ Cache Hit â€¢ ${latency}ms</span>`
				: `<span class="inline-flex items-center gap-1 rounded-full bg-gray-300 px-2 py-1 text-xs font-bold text-gray-700">ðŸ”„ Cache Miss â€¢ ${latency}ms</span>`;
			
			messageDiv.innerHTML = `
				<div class="flex-shrink-0 w-8 h-8 rounded-full bg-vibe-purple flex items-center justify-center text-white font-bold text-sm">
					AI
				</div>
				<div class="flex-1">
					<div class="neo-card bg-gray-100 p-3 text-sm">
						<p style="white-space: pre-line;">${text}</p>
					</div>
					<div class="mt-1 flex items-center gap-2">
						<span class="text-xs text-gray-500">${time}</span>
						${badge}
					</div>
				</div>
			`;
		}
		
		chatContainer.appendChild(messageDiv);
		chatContainer.scrollTop = chatContainer.scrollHeight;
	}

	async function sendSupportMessage(question) {
		if (!question.trim()) return;

		// Clear input
		const input = document.getElementById('support-input');
		input.value = '';

		// Add user message
		addMessage(question, true);

		// Show loading
		const loading = document.getElementById('support-loading');
		loading.classList.remove('hidden');

		try {
			const startTime = performance.now();
			
			// Call real VibeCache API
			const response = await fetch(VIBECACHE_API, {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
				},
				body: JSON.stringify({
					model: SUPPORT_MODEL,
					messages: [
						{ role: 'system', content: SUPPORT_SYSTEM_PROMPT },
						{ role: 'user', content: question }
					],
					temperature: 0.7,
					max_tokens: 500
				}),
			});

			const endTime = performance.now();
			const latency = Math.round(endTime - startTime);

			if (!response.ok) {
				throw new Error(`API error: ${response.status} ${response.statusText}`);
			}

			const data = await response.json();
			loading.classList.add('hidden');

			// Extract response
			const assistantMessage = data.choices[0].message.content;
			const tokens = data.usage?.total_tokens || 0;
			
			// Detect cache hit from response headers or timing (cache hits are <100ms)
			const isHit = latency < 100;
			
			addMessage(assistantMessage, false, isHit, latency);

			// Track metrics
			if (window.trackCacheRequest) {
				const tokensSaved = isHit ? tokens : 0;
				const costSaved = isHit ? (tokens / 1000000) * 0.15 : 0; // $0.15 per 1M tokens for gpt-4o-mini
				window.trackCacheRequest(isHit, latency, tokensSaved, costSaved);
			}
		} catch (error) {
			loading.classList.add('hidden');
			addMessage(`Error: ${error.message}\n\nPlease ensure the VibeCache API is accessible or try again later.`, false, false, 0);
			console.error('API Error:', error);
		}
	}

	function init() {
		const input = document.getElementById('support-input');
		const sendBtn = document.getElementById('support-send-btn');
		const quickBtns = document.querySelectorAll('.quick-question-btn');

		sendBtn.addEventListener('click', () => {
			sendSupportMessage(input.value);
		});

		input.addEventListener('keypress', (e) => {
			if (e.key === 'Enter') {
				sendSupportMessage(input.value);
			}
		});

		quickBtns.forEach(btn => {
			btn.addEventListener('click', () => {
				const question = btn.dataset.question;
				input.value = question;
				sendSupportMessage(question);
			});
		});
	}

	document.removeEventListener('DOMContentLoaded', init);
	document.addEventListener('DOMContentLoaded', init);
</script>
